# 书生·浦语大模型实战营-第二节课笔记

# 大模型及InterLM模型简介

## **什么是大模型**

​	大模型通常指的是机器学习或人工智能领域中参数数量巨大、拥有庞大计算能力和参数规模的模型。这些模型利用大量数据进行训练，并且拥有数十亿甚至数千亿个参数。大模型的出现和发展得益于增长的数据量、计算能力的提升以及算法优化等因素。这些模型在各种任务中展现出惊人的性能，比如自然语言处理、计算机视觉、语音识别等。这种模型通常采用深度神经网络结构，如 `Transformer`、`BERT`、`GPT`（ Generative Pre-trained Transformer ）等。

​	大模型的优势在于其能够捕捉和理解数据中更为复杂、抽象的特征和关系。通过大规模参数的学习，它们可以提高在各种任务上的泛化能力，并在未经过大量特定领域数据训练的情况下实现较好的表现。然而，大模型也面临着一些挑战，比如巨大的计算资源需求、高昂的训练成本、对大规模数据的依赖以及模型的可解释性等问题。因此，大模型的应用和发展也需要在性能、成本和道德等多个方面进行权衡和考量。

## **InternLM 模型全链条开源**

​	`InternLM` 是一个开源的轻量级训练框架，旨在支持大模型训练而无需大量的依赖。通过单一的代码库，它支持在拥有数千个 `GPU` 的大型集群上进行预训练，并在单个 `GPU` 上进行微调，同时实现了卓越的性能优化。在 `1024` 个 `GPU` 上训练时，`InternLM` 可以实现近 `90%` 的加速效率。

​	基于 `InternLM` 训练框架，上海人工智能实验室已经发布了两个开源的预训练模型：`InternLM-7B` 和 `InternLM-20B`。

​	`Lagent` 是一个轻量级、开源的基于大语言模型的智能体（agent）框架，支持用户快速地将一个大语言模型转变为多种类型的智能体，并提供了一些典型工具为大语言模型赋能。通过 `Lagent` 框架可以更好的发挥 `InternLM` 的全部性能。

# **InternLM-Chat-7B 智能对话 Demo**

- 环境使用A100（1/4）和 cuda11.7版本的conda镜像在InternStudio运行
- 使用的是pytorch 2.0.1
- 需要安装modelscope，transfomers，streamlit，sentencepiece 和accelerate库
- 使用平台`share`的目录下模型或者modelscope下载
- 在终端运行cli_demo.py实现一个简单的对话系统
- web-demo使用streamlit实现的

# **Lagent 智能体工具调用 Demo**

Lagent 是一个轻量级、开源的基于大语言模型的智能体（agent）框架，支持用户快速地将一个大语言模型转变为多种类型的智能体，并提供了一些典型工具为大语言模型赋能。通过 Lagent 框架可以更好的发挥 InternLM 的全部性能。

- 环境安装和模型下载同上
- 克隆仓库，并通过 `pip install -e .` 
- 界面可以选择模型进行交互

## **浦语·灵笔图文理解创作 Demo**

- 这里需要 A100(1/4)*2配置
- 与前面不同，使用gradio进行图文的交互，安装以下版本的库transformers==4.33.1 timm==0.4.12 sentencepiece==0.1.99 gradio==3.44.4 markdown2==2.4.10 xlsxwriter==3.1.2 einops accelerate
- 准备模型，克隆`InternLM-XComposer` 仓库的代码
- 可以生成图文进行理解创作，也可以多模态的实现图文交互问答