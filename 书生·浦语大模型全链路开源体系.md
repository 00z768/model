# 书生·浦语大模型全链路开源体系

## 大模型是发展通用人工智能的重要途径

发展方向：专用模型   ——   通用大模型

专用模型：针对特定的任务，一个模型去解决一个任务。  

​	例如：深度学习理论突破（深度置信网络）、大规模语音识别、人脸识别、围棋比赛（AlphaGo 4:1 李世磊）、AlphaFold去做蛋白质结构预测

通用大模型：一个模型应对多种任务、多种模态。  例如：ChatGPT



## 书生·浦语大模型系列

轻量级：InternLM-7B 			社区低成本可用最佳模型规模

中量级：InternLM-20B		   商业场景可开发定制高精度较小模型规模

重量级：InternLM-123B		 通用大语言模型能力全面覆盖千亿模型规模



## 从模型到应用

1. 模型选型（评测）
2. 业务场景是否复杂  否则直接到第7步：模型评测
3. 算力足够吗    否则进行参数微调，接着到第5步：是否需要环境交互
4. 继训/全参数微调
5. 是否需要环境交互  否则直接到第7步：模型评测
6. 构建智能体
7. 模型评测
8. 模型部署



## 书生·浦语全链条开源开放体系

### 数据：书生·万卷

2TB数据，包括文本数据、图像-文本数据集、视频数据

涵盖多种模态与任务

多模态融合、精细化处理、价值观对齐

还有OpenDataLab数据平台：拥有丰富多样的开放数据

###  预训练：InterLM-Train 预训练框架

并行训练，极致优化，数度可3600 tokens/sec/gpu

特点：高可扩展、极致性能优化、兼容主流、开箱即用

###  微调：XTuner 高效微调框架   

支持全参数微调 ,支持LoRA等低成本微调

常用方式：增量续训和有监督微调

增量续训：让基座模型学习到一些新知识，如某个垂类领域知识。

使用数据：文章、书籍、代码等。

有监督微调：让模型学会理解和遵循各种指令，或者注入少量领域知识。

使用数据：高质量的对话、问答数据。

高效微调框架  XTuner ：适配多种生态；适配多种硬件。

###  部署：LMDeploy

全链条部署，性能领先，每秒生成200+ tokens

大语言模型特点：内存开销巨大；动态Shape；模型结构相对简单。

技术挑战：设备（低存储设备如何部署）、推理（如何加速token的生成速度、如何解决动态Shape，让推理不间断、如何有效管理和利用内存）、服务（提升系统整体吞吐量、降低请求的平均响应时间）

部署方案：需要优化技术点

LMDeploy框架：对应不用接口、高效推理引擎、完备易用的工具链。

###  评测：OpenCompass评测工具

全方位评测 ，性能可复现，80套评测集，40万道题目

6个维度：学科、语言、知识、理解、推理、安全

OpenCompass开源评测平台架构：工具层、方法层、能力层、模型层

###  应用：Lagent和AgentLego

支持多种智能体 ，支持代码解释器等多种工具

大语言模型的局限性：最新信息和知识的获取、回复的可靠性、数学计算、工具使用和交互

轻量级智能体框架Lagent：支持多种类型的智能体能力、灵活支持多种大语言模型、简单易扩展，支持丰富工具

多模态智能体工具箱AgentLego：丰富的工具集合，尤其是提供了大量视觉、多模态相关领域的前沿算法功能；支持多个主流智能体系统；灵活的多模态工具调用接口，可以轻松支持各类输入输出格式的工具函数；一键式远程工具部署，轻松使用和调试大模型智能体。

